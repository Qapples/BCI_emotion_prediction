{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KVayZ-bw3cuR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.metrics import categorical_accuracy\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.signal import savgol_filter\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "import pandas as pd\n",
        "import dask.dataframe\n",
        "import csv\n",
        "import pdb\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numbers decribing the bci data\n",
        "num_features = 64\n",
        "number_of_people = 6\n",
        "bci_channel_count = 11"
      ],
      "metadata": {
        "id": "Tc0t7BjTvSPo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load bci feature and questoinnaire data from matlab files\n",
        "def flatten_bci_feature_data(raw_data, num_features):\n",
        "  data_size_x = int(raw_data.shape[0] / num_features)\n",
        "  data_size_y = num_features * bci_channel_count\n",
        "\n",
        "  data = np.array([])\n",
        "\n",
        "  for person_index in range(0, number_of_people):\n",
        "    temp_data = np.zeros((data_size_x, data_size_y))\n",
        "\n",
        "    for i in range(temp_data.shape[0]):\n",
        "        lr = i * num_features\n",
        "        ur = (i + 1) * num_features\n",
        "        temp_data[i] = raw_data[lr:ur, :, person_index].flatten('F')\n",
        "      \n",
        "    #pdb.set_trace()\n",
        "    data = temp_data if person_index == 0 else np.append(data, temp_data, axis=0)\n",
        "  \n",
        "  return data\n",
        "\n",
        "def stretch_arr(arr, length):\n",
        "    repeat = np.repeat(arr, length // len(arr) + 1)\n",
        "    return repeat[-length:]\n",
        "\n",
        "#there are only ~27 values for the moving average (which will be \"strected\" to the number of rows BCI data)\n",
        "def process_mov_avg_data(data_raw, num_rows_bci_data):\n",
        "    #MinMax normalization\n",
        "    data_raw = (data_raw - data_raw.min()) / (data_raw.max() - data_raw.min())\n",
        "    \n",
        "    return stretch_arr(data_raw, num_rows_bci_data)\n",
        "\n",
        "num_features = 64\n",
        "\n",
        "#\"bci_feature_data\" is x, questionnaire_data is y\n",
        "bci_feature_data = np.array(scipy.io.loadmat(\"./drive/MyDrive/BCI_data/encoded_data.mat\")[\"data\"])\n",
        "bci_feature_data = flatten_bci_feature_data(bci_feature_data, num_features)\n",
        "\n",
        "questionnaire_data = scipy.io.loadmat(\"./drive/MyDrive/BCI_data/Questionnaire.mat\")[\"Questionnaire\"][\"FearMovingAverage\"][0][0]\n",
        "questionnaire_data = np.array(questionnaire_data)\n",
        "questionnaire_data = process_mov_avg_data(questionnaire_data, bci_feature_data.shape[0])\n",
        "\n",
        "#\"smooth\" out survey data using savgol filter\n",
        "window_size = 11\n",
        "poly_order = 3\n",
        "questionnaire_data = savgol_filter(questionnaire_data, window_size, poly_order)"
      ],
      "metadata": {
        "id": "mIJLgTBN4YRr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method for building prediction model\n",
        "def build_model(input_length):\n",
        "  network = models.Sequential()\n",
        "\n",
        "  network.add(layers.Dense(256, activation=\"relu\", input_shape=(input_length,)))\n",
        "  #network.add(layers.Dropout(0.5))\n",
        "  network.add(layers.Dense(128, activation=\"relu\"))\n",
        "  #network.add(layers.Dropout(0.5))\n",
        "  network.add(layers.Dense(64, activation=\"relu\"))\n",
        "  #network.add(layers.Dropout(0.5))\n",
        "  network.add(layers.Dense(32, activation=\"relu\"))\n",
        "  network.add(layers.Dense(1))\n",
        "      \n",
        "  network.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
        "  \n",
        "  return network"
      ],
      "metadata": {
        "id": "fiOXYk-0_g1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model with kfold validation\n",
        "kfold_splits = 10\n",
        "epochs = 10\n",
        "batch_size = 4\n",
        "\n",
        "x = bci_feature_data\n",
        "y = questionnaire_data\n",
        "\n",
        "graph_fold_results = True\n",
        "\n",
        "kFold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "print('---------- CROSS FOLD VALIDATION ----------\\n')\n",
        "\n",
        "loss_arr = []\n",
        "score_arr = []\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kFold.split(x, y):\n",
        "  model = build_model(num_features * bci_channel_count)\n",
        "\n",
        "  print(f'---------------------- FOLD NO {fold_num} TRAINING BEGIN ----------------------\\n')\n",
        "\n",
        "  model.fit(x[train], y[train], batch_size=batch_size, epochs=epochs)\n",
        "  scores = model.evaluate(x[test], y[test])\n",
        "\n",
        "  loss_arr.append(scores[0])\n",
        "  loss_arr.append(scores[1])\n",
        "\n",
        "  print(f'---------------------- FOLD NO {fold_num} TRAINING END ----------------------\\n')\n",
        "\n",
        "  if not graph_fold_results: \n",
        "      continue\n",
        "  \n",
        "  test_pred = model.predict(x[test])\n",
        "  \n",
        "  fold_results_fig = plt.figure()\n",
        "  ax = fold_results_fig.add_axes([0.1,0.1,0.8,0.8])\n",
        "  ax.set_title(\"Actual vs. Prediction\")\n",
        "  \n",
        "  ax.plot(np.arange(y[test].shape[0]), y[test], label=\"actual\")\n",
        "  ax.plot(np.arange(test_pred.shape[0]), test_pred, label=\"prediction\")\n",
        "  ax.legend()\n",
        "\n",
        "  fold_num += 1\n",
        "\n",
        "print('------------ RESULTS PER FOLD ------------')\n",
        "for i in range(len(loss_arr)):\n",
        "    print(f'fold #{i}. Loss: {loss_arr[i]} - Score: {score_arr[i]}')\n",
        "    print('--------------')\n",
        "    \n",
        "print('\\n------- AVG ACROSS FOLDS -------')\n",
        "print(f'Avg loss: {np.mean(loss_arr)} +/- {np.std(loss_arr)}')\n",
        "print(f'Avg score: {np.mean(score_arr)} +/- {np.std(score_arr)}\\n')"
      ],
      "metadata": {
        "id": "YeSzF2YjozuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}